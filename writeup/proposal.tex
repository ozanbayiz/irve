\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{cleveref}       % smart cross-referencing
\usepackage{lipsum}         % Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

\title{Investigating Racial Semantics in Vision Transformer Representations Using FairFace}

\newif\ifuniqueAffiliation
% Comment to use multiple affiliations variant of author block 
\uniqueAffiliationtrue

\ifuniqueAffiliation % Standard variant of author block
\author{ Ozan Bayiz \\
	\texttt{ozanbayiz@berkeley.edu} \\
	%% examples of more authors
	\And
	Kapil Malladi \\
	\texttt{kapilmalladi@berkeley.edu} \\
	\AND
	Charlie Cooper \\
	\texttt{charlie.c@berkeley.edu} \\
	\And
	Raiyan Hammad Ausaf \\
	\texttt{raiyanausaf14@berkeley.edu} \\
}

% Uncomment to override  the `A preprint' in the header
\renewcommand{\headeright}{}
\renewcommand{\undertitle}{}
\renewcommand{\shorttitle}{}



\begin{document}
\maketitle

\begin{abstract}
We need more GPUs.
\end{abstract}


\section{"Coherent Story" Justifying our "Systematic Investigation"}
Recent high-profile failures of commercial vision systems — most notably the infamous Google Photos misclassification of Black individuals as “gorillas” — underscore the need for racial interpretability in deep learning models. Despite improvements in classification accuracy, modern vision systems often lack transparency in how sensitive attributes like race are internally represented. Our project aims to identify these ideas within a ViT model, and discover key features used by the model for classifying race. We use modern methods of mechanistic interpretability, such as sparse autoencoders and the superposition hypotheses to come up with, and empirically back, hypotheses.




\section{Method}
\subsection{Linear Probe}
\subsection{SAE}
\subsection{Collect Stats}
Table and visualization of the means in latent vector space
\subsection{Intervene}
What becomes an interesting question is how moving in the latent space truly affects the racial classification. It seems entirely plausible that moving along a vector defined between white and asian could bring the classification closer to Black. Or the average activation (of all racial means) being actually classified as Black or Indian, etc. due to proximity to the mean. If I am understanding this correctly, we will still be able to do a sanity check based on classifying the mean activations of each race ( I really hope that works)


\section{Components}
\subsection{Florence-2}
\subsection{SAE}
\subsection{Fairface}



\bibliographystyle{unsrtnat}
\bibliography{references}  %%% Uncomment this line and comment out the ``thebibliography'' section below to use the external .bib file (using bibtex) .


\end{document}
